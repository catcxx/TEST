package gps

import org.apache.spark.SparkContext

/**
 * Created by hadoop on 12/14/15.
 */
object getupcar {
  def main(args: Array[String]) {

    if (args.length < 1) {
      System.err.println("Usage: <file>")
      System.exit(1)
    }

    val sc = new SparkContext("local", "getswitch", "usr/spark/spark-1.0.0-bin-hadoop2/lib/spark-assembly-1.0.0-hadoop2.2.0.jar",
      null)
    val rawData = sc.textFile(args(0)).cache()
    val arrData = rawData.collect()

    var i =0
    var count = 0
    var oldstate = ' '
    var state = ' '
    while (i < arrData.length) {
      i = i+1
      state = arrData(i - 1).last
//      println(state)
      if(i==1){
        oldstate = state
      }else{
        if((oldstate.equals('4'))&&(state.equals('5'))){
          println(arrData(i-2)+"---"+arrData(i-1)+" picking up!")
          count = count + 1
        }
      }
      oldstate = state
    }
    println("picking up event: "+count)
  }
}
